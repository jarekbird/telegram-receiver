# PHASE3-031: Review caching strategies

**Section**: 5. Performance Review
**Subsection**: 5.3
**Task ID**: PHASE3-031

## Description

Review and improve caching strategies in the codebase to ensure best practices. This task focuses on analyzing existing caching implementations, identifying caching opportunities, and ensuring efficient cache usage throughout the application.

**Rails Implementation References:**

- `jarek-va/app/services/telegram_service.rb` - Bot client caching using `@bot ||=` singleton pattern (line 11). Note: The Rails implementation currently caches a single bot client instance, not per token. However, the documentation (`jarek-va/docs/MULTI_BOT_SETUP.md`) suggests per-token caching should be implemented for multi-bot support. The TypeScript implementation should support per-token caching using a Map/Object keyed by bot token.
- `jarek-va/app/services/cursor_runner_callback_service.rb` - Redis usage for state storage (not caching) with TTL (default 1 hour). Uses Redis keys with prefix `cursor_runner_callback:` for storing callback state.
- `jarek-va/app/services/tool_router.rb` - Memoization pattern using `@handlers ||= {}` for caching tool handlers (line 56).

## Checklist

### Existing Caching Implementation

- [ ] Review bot client caching implementation
  - Check if Telegram bot clients are cached per token (Rails uses `@bot ||=` for single instance, but TypeScript should support per-token caching for multi-bot support)
  - Verify in-memory cache (Map/Object) is used for bot clients, keyed by bot token
  - Review cache key strategy (should be per bot token, e.g., `Map<token, BotClient>`)
  - Check if cache invalidation is needed when bot tokens change (clear cache entry for updated token)
  - Verify cache is concurrent-safe for Node.js (Map is safe for concurrent reads, ensure writes are atomic)
  - Note: Rails implementation (`telegram_service.rb` line 11) only caches one bot client, but multi-bot documentation suggests per-token caching
- [ ] Review Redis usage for caching vs. state storage
  - Distinguish between Redis as cache (temporary, can be evicted) vs. state storage (required for operation)
  - Check callback state storage (`CursorRunnerCallbackService` uses Redis with TTL, but is state storage, not cache)
    - Reference: `jarek-va/app/services/cursor_runner_callback_service.rb` - Uses Redis keys with prefix `cursor_runner_callback:` and 1-hour TTL (DEFAULT_TTL = 3600)
    - This is required state for callback processing, not cache (should not be evicted before TTL)
  - Identify if any Redis data should be treated as cache vs. required state
  - Review if Redis is used appropriately for caching vs. other purposes
  - Verify callback state storage follows Rails pattern (key prefix, TTL, JSON serialization)

### Cache Opportunities

- [ ] Identify external API response caching opportunities
  - Check Telegram Bot API responses that could be cached (e.g., `get_webhook_info`, `get_file` metadata)
  - Review Cursor Runner API responses that might benefit from caching
  - Check ElevenLabs API responses for caching opportunities
  - Identify frequently accessed data that doesn't change often
- [ ] Review in-memory caching opportunities
  - Check for repeated calculations that could be cached
  - Identify configuration data that could be cached (e.g., system settings from MCP database)
  - Review parsed data structures that could be cached
  - Check for repeated validation results that could be cached
  - Review tool handler memoization (Rails `tool_router.rb` uses `@handlers ||= {}` pattern - should be implemented similarly in TypeScript)
- [ ] Review database query caching opportunities
  - Check MCP database queries (SystemSetting lookups, task queries) that could be cached
  - Identify frequently accessed data from shared SQLite database
  - Review if query results could be cached with appropriate TTLs
  - Check for patterns where same data is queried multiple times

### Cache Implementation Patterns

- [ ] Review cache key naming conventions
  - Verify consistent cache key patterns (e.g., `telegram:bot:{token}`, `config:{key}`)
  - Check that cache keys are descriptive and namespaced
  - Ensure no cache key collisions
  - Verify cache keys include versioning or invalidation strategy
- [ ] Review cache storage mechanisms
  - Check if in-memory cache (Map/Object) is appropriate for bot clients
  - Review if Redis should be used for distributed caching
  - Verify cache storage choice matches use case (single instance vs. multi-instance)
  - Check if cache size limits are needed (LRU eviction, max size)
- [ ] Review cache TTL (Time To Live) strategies
  - Verify TTL values are appropriate for cached data
  - Check if different TTLs are needed for different data types
  - Review if TTL should be configurable via environment variables
  - Verify TTL is set correctly (Rails callback state uses 1-hour TTL - `CursorRunnerCallbackService::DEFAULT_TTL = 3600`)
  - Note: TTL applies to Redis state storage, not in-memory caches (which typically don't expire unless invalidated)

### Cache Invalidation

- [ ] Review cache invalidation strategies
  - Check if cache invalidation is needed when data changes (e.g., bot token updates)
  - Review if TTL-based expiration is sufficient
  - Identify if manual cache invalidation is needed (e.g., admin endpoints)
  - Verify cache invalidation is implemented where needed
- [ ] Review cache invalidation patterns
  - Check for cache invalidation on updates (e.g., SystemSetting updates should invalidate config cache)
  - Review if cache invalidation is atomic (no race conditions)
  - Verify cache invalidation handles errors gracefully
  - Check if cache invalidation is logged for debugging

### Cache Performance and Monitoring

- [ ] Review cache hit/miss tracking
  - Check if cache hit/miss rates are tracked (metrics/logging)
  - Review if cache performance is monitored
  - Verify cache effectiveness can be measured
  - Check if cache statistics are available for debugging
- [ ] Review cache performance impact
  - Verify caching reduces external API calls
  - Check if caching reduces database queries
  - Review if caching improves response times
  - Verify caching doesn't introduce memory issues

### Cache Best Practices

- [ ] Review cache consistency
  - Check if cached data can become stale (is staleness acceptable?)
  - Verify cache consistency requirements for different data types
  - Review if cache warming is needed on application startup
  - Check if cache should be cleared on deployment
- [ ] Review cache error handling
  - Verify cache failures don't break application functionality
  - Check if graceful degradation is implemented (fallback to non-cached path)
  - Review error handling for cache operations
  - Verify cache errors are logged appropriately
- [ ] Review cache security
  - Check if cached data contains sensitive information
  - Verify cache keys don't expose sensitive data
  - Review if cache should be encrypted (if storing sensitive data)
  - Check if cache access is properly scoped

### Documentation and Strategy

- [ ] Document caching strategy
  - Document what is cached and why
  - Document cache key naming conventions
  - Document TTL policies for different data types
  - Document cache invalidation strategies
  - Create guidelines for future caching decisions
- [ ] Document cache implementation details
  - Document cache storage mechanisms used
  - Document cache size limits and eviction policies
  - Document cache monitoring and metrics
  - Document cache troubleshooting procedures

## Notes

- This task is part of Phase 3: Holistic Review and Best Practices
- Section: 5. Performance Review
- Focus on identifying issues and improvements
- Document findings and decisions

- Task can be completed independently by a single agent

## Related Tasks

- Previous: PHASE3-030
- Next: PHASE3-032

---

IMPORTANT: When updating system settings (SystemSetting model), you MUST use the cursor-runner-shared-sqlite MCP connection.

IMPORTANT: When working with tasks (creating, querying, updating, or deleting tasks), you MUST use the cursor-runner-shared-sqlite MCP connection. The tasks table is in the shared SQLite database at /app/shared_db/shared.sqlite3.

Tasks Table Schema:

- id: INTEGER PRIMARY KEY AUTOINCREMENT
- prompt: TEXT NOT NULL (the task prompt/description to be executed)
- status: INTEGER NOT NULL DEFAULT 0 (task status enum: 0=ready, 1=complete, 2=archived, 3=backlogged)
- createdat: DATETIME DEFAULT CURRENT_TIMESTAMP
- updatedat: DATETIME DEFAULT CURRENT_TIMESTAMP
- order: INTEGER DEFAULT 0 (lower numbers are processed first)
- uuid: TEXT (unique identifier, indexed)

Task Status Values:

- 0 = ready (ready to be processed by task operator)
- 1 = complete (task has been completed)
- 2 = archived (task has been archived)
- 3 = backlogged (task is in backlog, not ready for processing)

Task Management Examples:

- To create a ready task: INSERT INTO tasks (prompt, "order", status) VALUES ('your prompt here', 0, 0)
- To list ready tasks: SELECT \* FROM tasks WHERE status = 0 ORDER BY "order" ASC, id ASC
- To mark a task as complete: UPDATE tasks SET status = 1, updatedat = CURRENT_TIMESTAMP WHERE id = ?
- To archive a task: UPDATE tasks SET status = 2, updatedat = CURRENT_TIMESTAMP WHERE id = ?
- To backlog a task: UPDATE tasks SET status = 3, updatedat = CURRENT_TIMESTAMP WHERE id = ?
- To get next ready task: SELECT \* FROM tasks WHERE status = 0 ORDER BY "order" ASC, id ASC LIMIT 1

The task operator agent (when enabled) automatically processes tasks with status = 0 (ready), sending the prompt to cursor-runner for execution.

IMPORTANT: When working with cursor-agents (creating, listing, getting status, or deleting agents), use the Python scripts in /cursor/tools/cursor-agents/ directory. These scripts communicate with the cursor-agents service over HTTP:

Agent Management:

- To list all agents: python3 /cursor/tools/cursor-agents/list_agents.py
- To get agent status: python3 /cursor/tools/cursor-agents/get_agent_status.py --name <agent-name>
- To create an agent: python3 /cursor/tools/cursor-agents/create_agent.py --name <name> --target-url <url> [options]
  - Use --queue <queue-name> to assign the agent to a specific queue (defaults to "default" if not specified)
  - Use --schedule <cron-pattern> for recurring agents (e.g., "0 8 \* \* \*" for daily at 8 AM)
  - Use --one-time for one-time agents that run immediately
- To delete an agent: python3 /cursor/tools/cursor-agents/delete_agent.py --name <agent-name>

Queue Management:

- To list all queues: python3 /cursor/tools/cursor-agents/list_queues.py
- To get queue info: python3 /cursor/tools/cursor-agents/get_queue_info.py --queue-name <queue-name>
- To delete an empty queue: python3 /cursor/tools/cursor-agents/delete_queue.py --queue-name <queue-name>
  - Note: Cannot delete the "default" queue or queues with active jobs

Task Operator Management:

- To enable the task operator: python3 /cursor/tools/cursor-agents/enable_task_operator.py [--queue <queue-name>]
  - The task operator automatically processes tasks from the tasks table in the database
  - It checks for incomplete tasks (lowest order first) and sends them to cursor-runner
  - Automatically re-enqueues itself every 5 seconds while enabled
- To disable the task operator: python3 /cursor/tools/cursor-agents/disable_task_operator.py
  - Sets the task_operator system setting to false, stopping re-enqueueing

When creating an agent, the target URL should be the cursor-runner docker networked URL (http://cursor-runner:3001/cursor/iterate/async) with a prompt that this agent will later execute.

Queue Organization: Agents can be organized into queues to avoid queue bloat. By default, agents are created in the "default" queue. Use descriptive queue names like "daily-tasks", "hourly-sync", or "urgent-jobs" to group related agents together.

IMPORTANT: When creating one-time scripts (shell scripts, Python scripts, etc.), place them in /cursor/scripts. This directory is shared and persistent across container restarts. Do not create scripts in the repository directories or other temporary locations.
