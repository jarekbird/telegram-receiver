# PHASE4-004: Run complexity analysis

**Section**: 1. Automated Code Smell Detection
**Subsection**: 1.4
**Task ID**: PHASE4-004

## Description

Run comprehensive complexity analysis to identify high-complexity functions and code sections that may impact code quality and maintainability. This task focuses on measuring cyclomatic complexity, cognitive complexity, and other complexity metrics to identify areas that need refactoring or simplification.

## Current State

The project currently has:

- **ESLint** configured with TypeScript rules (PHASE4-001)
- **Prettier** configured for code formatting (PHASE4-002)
- **SonarQube or similar tool** may be set up (PHASE4-003)
- Basic linting and formatting scripts in package.json

**Missing**: Comprehensive complexity analysis that provides:

- Cyclomatic complexity metrics for all functions
- Cognitive complexity measurements
- Identification of high-complexity functions (>10 cyclomatic complexity)
- Complexity trends and baselines
- Integration with existing tooling (ESLint, SonarQube)
- Automated complexity reporting

## Tool Options

Consider the following options for complexity analysis:

1. **ESLint with complexity rules** (Recommended for quick setup)
   - `complexity` rule - measures cyclomatic complexity and sets thresholds
   - Already integrated with existing ESLint setup
   - Can be configured in `.eslintrc.json`
   - Free and lightweight
   - Note: ESLint's `complexity` rule syntax is `complexity: ["warn", 10]` where 10 is the maximum allowed complexity

2. **SonarQube/SonarCloud** (If PHASE4-003 is completed)
   - Comprehensive complexity analysis
   - Cyclomatic complexity and cognitive complexity
   - Visual complexity reports
   - Integration with existing SonarQube setup
   - Provides complexity ratings and trends

3. **ts-complexity** (npm package)
   - TypeScript-specific complexity analysis
   - Command-line tool
   - Generates complexity reports
   - Can be integrated into npm scripts
   - **Note**: This package is quite old (last updated 2017) and may not be actively maintained. Consider alternatives if compatibility issues arise.

4. **plato** (JavaScript complexity visualizer)
   - Generates visual complexity reports
   - HTML reports with complexity metrics
   - Historical tracking
   - Free and open-source

5. **jscpd** (Copy/paste detector with complexity)
   - Detects code duplication
   - Also provides complexity metrics
   - Can complement other tools

## Complexity Thresholds

Recommended complexity thresholds:

- **Cyclomatic Complexity**:
  - Low: 1-5 (acceptable)
  - Medium: 6-10 (review recommended)
  - High: 11-20 (refactoring recommended)
  - Very High: 21+ (refactoring required)

- **Cognitive Complexity**:
  - Low: 1-8 (acceptable)
  - Medium: 9-15 (review recommended)
  - High: 16+ (refactoring recommended)

## Checklist

### Tool Selection and Setup

- [ ] Research and compare complexity analysis tool options
- [ ] Choose appropriate tool(s) based on project needs and existing setup
- [ ] Install chosen tool(s) as dev dependencies (if npm packages)
- [ ] Configure ESLint complexity rules (if using ESLint approach)
- [ ] Set up complexity thresholds in tool configuration
- [ ] Add complexity analysis script to package.json

### ESLint Complexity Configuration (Recommended)

- [ ] Add `complexity` rule to `.eslintrc.json` with threshold (recommended: 10)
- [ ] Configure additional complexity-related rules:
  - `max-depth` - maximum nesting depth (recommended: 4)
  - `max-lines-per-function` - maximum lines per function (recommended: 50)
  - `max-params` - maximum function parameters (recommended: 5)
- [ ] Test ESLint complexity rules on `src/` directory
- [ ] Adjust thresholds based on initial results

### Running Complexity Analysis

- [ ] Run initial complexity analysis on `src/` directory (main source code)
- [ ] Optionally run analysis on `tests/` directory (test code complexity)
- [ ] Generate complexity report (JSON, HTML, or console output)
- [ ] Identify all functions with complexity > 10
- [ ] Identify all functions with complexity > 20 (critical)
- [ ] Calculate average complexity per file
- [ ] Calculate average complexity per function
- [ ] Identify files with highest average complexity

### Analysis and Documentation

- [ ] Review complexity metrics and identify patterns
- [ ] Document all high-complexity functions (>10):
  - Function name and location
  - Complexity score
  - Reason for high complexity
  - Suggested refactoring approach
- [ ] Create prioritized list of complexity issues:
  - Critical: Complexity > 20
  - High: Complexity 11-20
  - Medium: Complexity 6-10
- [ ] Document complexity baseline metrics:
  - Total number of functions analyzed
  - Average complexity score
  - Number of functions exceeding thresholds
  - Most complex functions (top 10)
- [ ] Create complexity report document (markdown or HTML)

### Integration

- [ ] Integrate complexity checks into CI/CD pipeline (if applicable)
- [ ] Add complexity analysis to pre-commit hooks (optional)
- [ ] Configure complexity gates (fail build if complexity exceeds threshold)
- [ ] Set up automated complexity reporting
- [ ] Document how to run complexity analysis locally

### Review and Validation

- [ ] Verify complexity analysis runs successfully
- [ ] Verify reports are generated correctly
- [ ] Review complexity findings for accuracy
- [ ] Validate that all high-complexity functions are identified
- [ ] Ensure complexity metrics align with code review findings
- [ ] Test CI/CD integration (if configured)

## Configuration Example (ESLint)

Add to `.eslintrc.json`:

```json
{
  "rules": {
    "complexity": ["warn", 10],
    "max-depth": ["warn", 4],
    "max-lines-per-function": ["warn", { "max": 50, "skipBlankLines": true, "skipComments": true }],
    "max-params": ["warn", 5],
    "@typescript-eslint/explicit-function-return-type": "off"
  }
}
```

**Note**: The `complexity` rule syntax is `complexity: ["warn", 10]` where `10` is the maximum allowed cyclomatic complexity. This is different from some other ESLint rules that use an object format.

## Configuration Example (package.json script)

Add complexity analysis script:

```json
{
  "scripts": {
    "complexity": "ts-complexity src --threshold 10",
    "complexity:report": "ts-complexity src --threshold 10 --format html --output complexity-report.html",
    "complexity:eslint": "eslint src --ext .ts --format json --output-file complexity-report.json"
  }
}
```

**Note**: If using ESLint for complexity analysis, the `complexity:eslint` script will generate a JSON report. For HTML reports with ESLint, consider using `eslint-html-reporter` or similar tools.

## Notes

- This task is part of Phase 4: Code Quality Audit
- Section: 1. Automated Code Smell Detection
- Focus on identifying and fixing code quality issues
- Document all findings and improvements
- Complexity analysis should complement, not replace, code reviews
- Start with reasonable thresholds and adjust based on baseline results
- Consider both cyclomatic and cognitive complexity
- High complexity doesn't always mean bad code - context matters
- Use complexity metrics as a guide, not an absolute rule
- Integration with SonarQube (if set up in PHASE4-003) provides the most comprehensive analysis
- Task can be completed independently by a single agent
- **Important**: When configuring ESLint complexity rules, use the correct syntax: `complexity: ["warn", 10]` (not `{ "max": 10 }`). The number directly represents the maximum allowed complexity.
- Analysis should primarily focus on the `src/` directory, which contains the main application code

## Related Tasks

- Previous: PHASE4-003
- Next: PHASE4-005

---

IMPORTANT: When updating system settings (SystemSetting model), you MUST use the cursor-runner-shared-sqlite MCP connection.

IMPORTANT: When working with tasks (creating, querying, updating, or deleting tasks), you MUST use the cursor-runner-shared-sqlite MCP connection. The tasks table is in the shared SQLite database at /app/shared_db/shared.sqlite3.

Tasks Table Schema:

- id: INTEGER PRIMARY KEY AUTOINCREMENT
- prompt: TEXT NOT NULL (the task prompt/description to be executed)
- status: INTEGER NOT NULL DEFAULT 0 (task status enum: 0=ready, 1=complete, 2=archived, 3=backlogged)
- createdat: DATETIME DEFAULT CURRENT_TIMESTAMP
- updatedat: DATETIME DEFAULT CURRENT_TIMESTAMP
- order: INTEGER DEFAULT 0 (lower numbers are processed first)
- uuid: TEXT (unique identifier, indexed)

Task Status Values:

- 0 = ready (ready to be processed by task operator)
- 1 = complete (task has been completed)
- 2 = archived (task has been archived)
- 3 = backlogged (task is in backlog, not ready for processing)

Task Management Examples:

- To create a ready task: INSERT INTO tasks (prompt, "order", status) VALUES ('your prompt here', 0, 0)
- To list ready tasks: SELECT \* FROM tasks WHERE status = 0 ORDER BY "order" ASC, id ASC
- To mark a task as complete: UPDATE tasks SET status = 1, updatedat = CURRENT_TIMESTAMP WHERE id = ?
- To archive a task: UPDATE tasks SET status = 2, updatedat = CURRENT_TIMESTAMP WHERE id = ?
- To backlog a task: UPDATE tasks SET status = 3, updatedat = CURRENT_TIMESTAMP WHERE id = ?
- To get next ready task: SELECT \* FROM tasks WHERE status = 0 ORDER BY "order" ASC, id ASC LIMIT 1

The task operator agent (when enabled) automatically processes tasks with status = 0 (ready), sending the prompt to cursor-runner for execution.

IMPORTANT: When working with cursor-agents (creating, listing, getting status, or deleting agents), use the Python scripts in /cursor/tools/cursor-agents/ directory. These scripts communicate with the cursor-agents service over HTTP:

Agent Management:

- To list all agents: python3 /cursor/tools/cursor-agents/list_agents.py
- To get agent status: python3 /cursor/tools/cursor-agents/get_agent_status.py --name <agent-name>
- To create an agent: python3 /cursor/tools/cursor-agents/create_agent.py --name <name> --target-url <url> [options]
  - Use --queue <queue-name> to assign the agent to a specific queue (defaults to "default" if not specified)
  - Use --schedule <cron-pattern> for recurring agents (e.g., "0 8 \* \* \*" for daily at 8 AM)
  - Use --one-time for one-time agents that run immediately
- To delete an agent: python3 /cursor/tools/cursor-agents/delete_agent.py --name <agent-name>

Queue Management:

- To list all queues: python3 /cursor/tools/cursor-agents/list_queues.py
- To get queue info: python3 /cursor/tools/cursor-agents/get_queue_info.py --queue-name <queue-name>
- To delete an empty queue: python3 /cursor/tools/cursor-agents/delete_queue.py --queue-name <queue-name>
  - Note: Cannot delete the "default" queue or queues with active jobs

Task Operator Management:

- To enable the task operator: python3 /cursor/tools/cursor-agents/enable_task_operator.py [--queue <queue-name>]
  - The task operator automatically processes tasks from the tasks table in the database
  - It checks for incomplete tasks (lowest order first) and sends them to cursor-runner
  - Automatically re-enqueues itself every 5 seconds while enabled
- To disable the task operator: python3 /cursor/tools/cursor-agents/disable_task_operator.py
  - Sets the task_operator system setting to false, stopping re-enqueueing

When creating an agent, the target URL should be the cursor-runner docker networked URL (http://cursor-runner:3001/cursor/iterate/async) with a prompt that this agent will later execute.

Queue Organization: Agents can be organized into queues to avoid queue bloat. By default, agents are created in the "default" queue. Use descriptive queue names like "daily-tasks", "hourly-sync", or "urgent-jobs" to group related agents together.

IMPORTANT: When creating one-time scripts (shell scripts, Python scripts, etc.), place them in /cursor/scripts. This directory is shared and persistent across container restarts. Do not create scripts in the repository directories or other temporary locations.
