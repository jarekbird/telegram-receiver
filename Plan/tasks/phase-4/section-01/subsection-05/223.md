# PHASE4-005: Detect code duplication

**Section**: 1. Automated Code Smell Detection
**Subsection**: 1.5
**Task ID**: PHASE4-005

## Description

Set up and run comprehensive code duplication detection to identify duplicate code blocks, patterns, and structures that impact code quality and maintainability. This task focuses on configuring duplication detection tools, detecting copy-paste code, identifying similar code blocks, and documenting opportunities for code consolidation through refactoring.

## Current State

The project currently has:

- **ESLint** configured with TypeScript rules (PHASE4-001)
- **Prettier** configured for code formatting (PHASE4-002)
- **SonarQube or similar tool** may be set up (PHASE4-003)
- **Complexity analysis** may be completed (PHASE4-004)
- Basic linting and formatting scripts in package.json

**Missing**: Comprehensive code duplication detection that provides:

- Identification of duplicate code blocks across the codebase
- Measurement of duplication percentage
- Detection of similar (not identical) code patterns
- Prioritization of duplication issues by severity
- Integration with existing tooling (ESLint, SonarQube)
- Automated duplication reporting

## Tool Options

Consider the following options for code duplication detection:

1. **jscpd** (JavaScript Copy/Paste Detector) (Recommended)
   - TypeScript and JavaScript support
   - Configurable similarity threshold
   - Multiple output formats (console, JSON, HTML)
   - Can be integrated into npm scripts
   - Free and actively maintained
   - Supports ignoring patterns (node_modules, dist, tests)

2. **SonarQube/SonarCloud** (If PHASE4-003 is completed)
   - Built-in duplication detection
   - Visual duplication reports
   - Integration with existing SonarQube setup
   - Provides duplication percentage metrics
   - Historical tracking of duplication trends

3. **PMD Copy/Paste Detector (CPD)**
   - Supports TypeScript/JavaScript
   - Command-line tool
   - Configurable minimum token count
   - XML and text report formats
   - Can be integrated into CI/CD

4. **ESLint plugin: eslint-plugin-no-secrets**
   - While primarily for secrets detection, can help identify patterns
   - Can be combined with other tools

5. **TypeScript-specific analyzers**
   - Some TypeScript-aware tools can detect structural duplication
   - Better at identifying semantically similar code

## Duplication Thresholds

Recommended duplication detection thresholds:

- **Minimum tokens**: 50-100 tokens (default: 50)
  - Lower values detect smaller duplicates (may have false positives)
  - Higher values detect larger duplicates (more significant issues)
- **Similarity threshold**: 80-100% (default: 80%)
  - 100% = exact duplicates
  - 80-99% = near-duplicates (similar code with minor variations)
- **Duplication percentage targets**:
  - Excellent: < 3% duplication
  - Good: 3-5% duplication
  - Acceptable: 5-10% duplication
  - Needs improvement: > 10% duplication

## Checklist

### Tool Selection and Setup

- [ ] Research and compare code duplication detection tool options
- [ ] Choose appropriate tool(s) based on project needs and existing setup
- [ ] Install chosen tool(s) as dev dependencies (if npm packages)
- [ ] Configure tool with appropriate thresholds and ignore patterns
- [ ] Add duplication detection script to package.json
- [ ] Configure ignore patterns (node_modules, dist, coverage, tests directory if desired)

### jscpd Configuration (Recommended)

- [ ] Install jscpd: `npm install --save-dev jscpd`
- [ ] Create `.jscpdrc.json` configuration file in project root
- [ ] Configure minimum tokens threshold (recommended: 50)
- [ ] Configure similarity threshold (recommended: 80%)
- [ ] Set ignore patterns:
  - `**/node_modules/**` (exclude dependencies)
  - `**/dist/**` (exclude compiled output)
  - `**/coverage/**` (exclude test coverage reports)
  - `**/tests/**` (exclude test directory - tests are in separate `tests/` directory)
  - `**/*.test.ts` (optional, if test files are co-located with source)
  - `**/*.spec.ts` (optional, if spec files are co-located with source)
- [ ] Configure report formats (console, JSON, HTML)
- [ ] Configure report output directory (create `reports/` directory if needed, or use existing directory)
- [ ] Test jscpd configuration on codebase

### Running Duplication Detection

- [ ] Run initial duplication detection on entire codebase
- [ ] Generate duplication report (JSON, HTML, or console output)
- [ ] Identify all duplicate code blocks:
  - Exact duplicates (100% similarity)
  - Near-duplicates (80-99% similarity)
- [ ] Calculate overall duplication percentage
- [ ] Identify files with highest duplication
- [ ] Identify most duplicated code patterns
- [ ] Count number of duplicate blocks found

### Analysis and Documentation

- [ ] Review duplication findings and identify patterns:
  - Common duplication patterns (e.g., error handling, validation logic)
  - Files with most duplication
  - Functions/methods that appear duplicated
- [ ] Document all significant duplicate code blocks:
  - File locations and line numbers
  - Similarity percentage
  - Size of duplicate block (lines/tokens)
  - Reason for duplication (if apparent)
  - Suggested refactoring approach
- [ ] Create prioritized list of duplication issues:
  - Critical: Large exact duplicates (>100 lines, 100% similarity)
  - High: Medium exact duplicates (50-100 lines, 100% similarity)
  - Medium: Large near-duplicates (>100 lines, 80-99% similarity)
  - Low: Small duplicates (<50 lines)
- [ ] Document duplication baseline metrics:
  - Total duplication percentage
  - Number of duplicate blocks found
  - Average size of duplicate blocks
  - Most duplicated files (top 10)
  - Most common duplication patterns
- [ ] Create duplication report document (markdown or HTML)

### Integration

- [ ] Integrate duplication checks into CI/CD pipeline (if applicable)
- [ ] Add duplication detection to pre-commit hooks (optional)
- [ ] Configure duplication gates (warn/fail build if duplication exceeds threshold)
- [ ] Set up automated duplication reporting
- [ ] Document how to run duplication detection locally

### Review and Validation

- [ ] Verify duplication detection runs successfully
- [ ] Verify reports are generated correctly
- [ ] Review duplication findings for accuracy
- [ ] Validate that all significant duplicates are identified
- [ ] Ensure duplication metrics align with code review findings
- [ ] Test CI/CD integration (if configured)
- [ ] Verify ignore patterns work correctly

## Configuration Example (jscpd)

Create `.jscpdrc.json`:

```json
{
  "threshold": 80,
  "minTokens": 50,
  "ignore": [
    "**/node_modules/**",
    "**/dist/**",
    "**/coverage/**",
    "**/tests/**",
    "**/*.test.ts",
    "**/*.spec.ts"
  ],
  "reporters": ["console", "json", "html"],
  "reportersOptions": {
    "json": {
      "output": "reports/jscpd-report.json"
    },
    "html": {
      "output": "reports/jscpd-report.html"
    }
  }
}
```

**Note**: The `reports/` directory will be created automatically by jscpd if it doesn't exist. Alternatively, you can use an existing directory like `coverage/` or create the directory manually before running the tool.

## Configuration Example (package.json script)

Add duplication detection script:

```json
{
  "scripts": {
    "duplication": "jscpd src --threshold 80 --min-tokens 50",
    "duplication:report": "jscpd src --threshold 80 --min-tokens 50 --reporters html --reporters json --output reports/jscpd"
  }
}
```

## Notes

- This task is part of Phase 4: Code Quality Audit
- Section: 1. Automated Code Smell Detection
- Focus on identifying and fixing code quality issues
- Document all findings and improvements
- Code duplication detection should complement, not replace, code reviews
- Start with reasonable thresholds and adjust based on baseline results
- Some duplication may be acceptable (e.g., test fixtures, configuration patterns)
- Focus on functional duplication that impacts maintainability
- Integration with SonarQube (if set up in PHASE4-003) provides the most comprehensive analysis
- Consider both exact duplicates and near-duplicates (similar patterns)
- Task can be completed independently by a single agent

## Related Tasks

- Previous: PHASE4-004
- Next: PHASE4-006

## Definition of Done

This document defines the criteria for task completion. The review agent uses these definitions to evaluate whether a task has been completed successfully.

### 1. CODE/FILE WRITING TASKS

**Description**: Tasks that involve writing, creating, modifying, or implementing SOURCE CODE FILES that need to be committed to git.

**Definition of Done**: "A Pull Request was created OR code was pushed to origin with the task complete"

**Examples**:
- Creating new source code files
- Modifying existing source code files
- Implementing features, functions, classes, modules
- Writing tests, specs
- Refactoring code
- Fixing bugs in source code

### 2. SYSTEM/ENVIRONMENT OPERATION TASKS

**Description**: Tasks involving installing dependencies, running builds, installing packages, running migrations, executing install scripts, etc.

**Definition of Done**: "The required operation must complete successfully with no errors, and the expected artifacts must be created. If any part of the operation fails, the task is NOT complete."

**Important Notes**:
- Installing dependencies requires packages to actually be installed successfully
- Updating package.json is NOT enough
- If the output mentions environmental issues, errors, warnings, or failed operations, the task is NOT complete

**Examples**:
- Installing npm packages, pip packages, gem dependencies
- Running database migrations
- Building/compiling projects
- Setting up development environments
- Running install scripts

### 3. SIMPLE REQUESTS/QUESTIONS/DATA OPERATIONS

**Description**: Tasks involving asking questions, requesting information, explanations, clarifications, database queries/updates, data manipulation, executing scripts/commands that don't create source code files, etc.

**Definition of Done**: "The request was completed or the question was answered"

**Examples**:
- Answering questions
- Providing explanations
- Querying databases
- Reading/updating data
- Executing commands that don't create source code files
- Information gathering tasks



---

IMPORTANT: When updating system settings (SystemSetting model), you MUST use the cursor-runner-shared-sqlite MCP connection.

IMPORTANT: When working with tasks (creating, querying, updating, or deleting tasks), you MUST use the cursor-runner-shared-sqlite MCP connection. The tasks table is in the shared SQLite database at /app/shared_db/shared.sqlite3.

Tasks Table Schema:

- id: INTEGER PRIMARY KEY AUTOINCREMENT
- prompt: TEXT NOT NULL (the task prompt/description to be executed)
- status: INTEGER NOT NULL DEFAULT 0 (task status enum: 0=ready, 1=complete, 2=archived, 3=backlogged)
- createdat: DATETIME DEFAULT CURRENT_TIMESTAMP
- updatedat: DATETIME DEFAULT CURRENT_TIMESTAMP
- order: INTEGER DEFAULT 0 (lower numbers are processed first)
- uuid: TEXT (unique identifier, indexed)

Task Status Values:

- 0 = ready (ready to be processed by task operator)
- 1 = complete (task has been completed)
- 2 = archived (task has been archived)
- 3 = backlogged (task is in backlog, not ready for processing)

Task Management Examples:

- To create a ready task: INSERT INTO tasks (prompt, "order", status) VALUES ('your prompt here', 0, 0)
- To list ready tasks: SELECT \* FROM tasks WHERE status = 0 ORDER BY "order" ASC, id ASC
- To mark a task as complete: UPDATE tasks SET status = 1, updatedat = CURRENT_TIMESTAMP WHERE id = ?
- To archive a task: UPDATE tasks SET status = 2, updatedat = CURRENT_TIMESTAMP WHERE id = ?
- To backlog a task: UPDATE tasks SET status = 3, updatedat = CURRENT_TIMESTAMP WHERE id = ?
- To get next ready task: SELECT \* FROM tasks WHERE status = 0 ORDER BY "order" ASC, id ASC LIMIT 1

The task operator agent (when enabled) automatically processes tasks with status = 0 (ready), sending the prompt to cursor-runner for execution.

IMPORTANT: When working with cursor-agents (creating, listing, getting status, or deleting agents), use the Python scripts in /cursor/tools/cursor-agents/ directory. These scripts communicate with the cursor-agents service over HTTP:

Agent Management:

- To list all agents: python3 /cursor/tools/cursor-agents/list_agents.py
- To get agent status: python3 /cursor/tools/cursor-agents/get_agent_status.py --name <agent-name>
- To create an agent: python3 /cursor/tools/cursor-agents/create_agent.py --name <name> --target-url <url> [options]
  - Use --queue <queue-name> to assign the agent to a specific queue (defaults to "default" if not specified)
  - Use --schedule <cron-pattern> for recurring agents (e.g., "0 8 \* \* \*" for daily at 8 AM)
  - Use --one-time for one-time agents that run immediately
- To delete an agent: python3 /cursor/tools/cursor-agents/delete_agent.py --name <agent-name>

Queue Management:

- To list all queues: python3 /cursor/tools/cursor-agents/list_queues.py
- To get queue info: python3 /cursor/tools/cursor-agents/get_queue_info.py --queue-name <queue-name>
- To delete an empty queue: python3 /cursor/tools/cursor-agents/delete_queue.py --queue-name <queue-name>
  - Note: Cannot delete the "default" queue or queues with active jobs

Task Operator Management:

- To enable the task operator: python3 /cursor/tools/cursor-agents/enable_task_operator.py [--queue <queue-name>]
  - The task operator automatically processes tasks from the tasks table in the database
  - It checks for incomplete tasks (lowest order first) and sends them to cursor-runner
  - Automatically re-enqueues itself every 5 seconds while enabled
- To disable the task operator: python3 /cursor/tools/cursor-agents/disable_task_operator.py
  - Sets the task_operator system setting to false, stopping re-enqueueing

When creating an agent, the target URL should be the cursor-runner docker networked URL (http://cursor-runner:3001/cursor/iterate/async) with a prompt that this agent will later execute.

Queue Organization: Agents can be organized into queues to avoid queue bloat. By default, agents are created in the "default" queue. Use descriptive queue names like "daily-tasks", "hourly-sync", or "urgent-jobs" to group related agents together.

IMPORTANT: When creating one-time scripts (shell scripts, Python scripts, etc.), place them in /cursor/scripts. This directory is shared and persistent across container restarts. Do not create scripts in the repository directories or other temporary locations.
