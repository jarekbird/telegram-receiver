# PHASE2-009: Create Redis connection utility

**Section**: 2. Redis Integration
**Subsection**: 2.3
**Task ID**: PHASE2-009

## Description

Create a Redis connection utility that provides a singleton Redis client instance for use throughout the application. This utility centralizes Redis client creation and provides a consistent interface for Redis connectivity.

**Rails Implementation Reference:**

- `app/services/cursor_runner_callback_service.rb` - Shows Redis client initialization pattern:
  - Uses `Redis.new(url: redis_url)` to create client
  - Supports dependency injection (can pass `redis_client` or `redis_url`)
  - Falls back to `ENV.fetch('REDIS_URL', 'redis://localhost:6379/0')`
  - In Docker: `REDIS_URL=redis://redis:6379/0` (shared Redis instance)
  - Local development: Falls back to `redis://localhost:6379/0`

**Node.js Implementation:**

- Use `ioredis` package (already in dependencies, used for direct Redis operations)
- Implement singleton pattern to ensure single Redis connection instance
- Use Redis configuration from `src/config/redis.ts` (created in PHASE2-008)
- Support dependency injection for testing (allow passing mock Redis client)
- Basic error handling (connection errors, initialization errors)
- Advanced error handling (reconnection logic, event listeners) will be added in PHASE2-010

## Checklist

- [ ] Create `src/utils/redis.ts` file
- [ ] Import `Redis` from `ioredis` package
- [ ] Import `redisConfig` from `src/config/redis.ts` (PHASE2-008)
- [ ] Implement singleton pattern:
  - [ ] Create private `redisClient` variable (null initially)
  - [ ] Create `getRedisClient()` function that returns singleton instance
  - [ ] Initialize client on first access using `redisConfig.url`
  - [ ] Return existing client on subsequent calls
- [ ] Support dependency injection:
  - [ ] Add optional parameter to `getRedisClient()` to allow passing custom Redis client (for testing)
  - [ ] If custom client provided, use it instead of creating new instance
  - [ ] This matches Rails pattern where `redis_client` parameter takes precedence over `redis_url`
- [ ] Add basic error handling:
  - [ ] Wrap client initialization in try-catch
  - [ ] Log initialization errors
  - [ ] Throw meaningful errors if initialization fails
- [ ] Export `getRedisClient()` function as default export
- [ ] Add TypeScript type definitions:
  - [ ] Import `Redis` type from `ioredis`
  - [ ] Type the return value of `getRedisClient()`
- [ ] Add JSDoc comments documenting:
  - [ ] Singleton behavior
  - [ ] Dependency injection support
  - [ ] Usage examples
- [ ] Ensure implementation matches Rails pattern (environment variable with default, dependency injection support)

## Notes

- This task is part of Phase 2: File-by-File Conversion
- Section: 2. Redis Integration
- **Rails Files to Reference:**
  - `jarek-va/app/services/cursor_runner_callback_service.rb` - Redis client initialization pattern (lines 15-21)
- **Dependencies:**
  - Requires PHASE2-008 (Redis configuration) to be completed first
  - Uses `ioredis` package (already in package.json dependencies)
- **Implementation Details:**
  - Singleton pattern ensures single Redis connection instance across the application
  - Dependency injection support allows passing mock clients in tests
  - Basic error handling covers initialization failures
  - Advanced error handling (reconnection, event listeners) is handled in PHASE2-010
- **Default Redis URL:** `redis://localhost:6379/0` (matches Rails default)
- **Docker Redis URL:** `redis://redis:6379/0` (set via REDIS_URL environment variable)
- Task can be completed independently by a single agent (after PHASE2-008 is complete)

## Related Tasks

- Previous: PHASE2-008
- Next: PHASE2-010

## Definition of Done

This document defines the criteria for task completion. The review agent uses these definitions to evaluate whether a task has been completed successfully.

### 1. CODE/FILE WRITING TASKS

**Description**: Tasks that involve writing, creating, modifying, or implementing SOURCE CODE FILES that need to be committed to git.

**Definition of Done**: "A Pull Request was created OR code was pushed to origin with the task complete"

**Examples**:
- Creating new source code files
- Modifying existing source code files
- Implementing features, functions, classes, modules
- Writing tests, specs
- Refactoring code
- Fixing bugs in source code

### 2. SYSTEM/ENVIRONMENT OPERATION TASKS

**Description**: Tasks involving installing dependencies, running builds, installing packages, running migrations, executing install scripts, etc.

**Definition of Done**: "The required operation must complete successfully with no errors, and the expected artifacts must be created. If any part of the operation fails, the task is NOT complete."

**Important Notes**:
- Installing dependencies requires packages to actually be installed successfully
- Updating package.json is NOT enough
- If the output mentions environmental issues, errors, warnings, or failed operations, the task is NOT complete

**Examples**:
- Installing npm packages, pip packages, gem dependencies
- Running database migrations
- Building/compiling projects
- Setting up development environments
- Running install scripts

### 3. SIMPLE REQUESTS/QUESTIONS/DATA OPERATIONS

**Description**: Tasks involving asking questions, requesting information, explanations, clarifications, database queries/updates, data manipulation, executing scripts/commands that don't create source code files, etc.

**Definition of Done**: "The request was completed or the question was answered"

**Examples**:
- Answering questions
- Providing explanations
- Querying databases
- Reading/updating data
- Executing commands that don't create source code files
- Information gathering tasks



---

IMPORTANT: When updating system settings (SystemSetting model), you MUST use the cursor-runner-shared-sqlite MCP connection.

IMPORTANT: When working with tasks (creating, querying, updating, or deleting tasks), you MUST use the cursor-runner-shared-sqlite MCP connection. The tasks table is in the shared SQLite database at /app/shared_db/shared.sqlite3.

Tasks Table Schema:

- id: INTEGER PRIMARY KEY AUTOINCREMENT
- prompt: TEXT NOT NULL (the task prompt/description to be executed)
- status: INTEGER NOT NULL DEFAULT 0 (task status enum: 0=ready, 1=complete, 2=archived, 3=backlogged)
- createdat: DATETIME DEFAULT CURRENT_TIMESTAMP
- updatedat: DATETIME DEFAULT CURRENT_TIMESTAMP
- order: INTEGER DEFAULT 0 (lower numbers are processed first)
- uuid: TEXT (unique identifier, indexed)

Task Status Values:

- 0 = ready (ready to be processed by task operator)
- 1 = complete (task has been completed)
- 2 = archived (task has been archived)
- 3 = backlogged (task is in backlog, not ready for processing)

Task Management Examples:

- To create a ready task: INSERT INTO tasks (prompt, "order", status) VALUES ('your prompt here', 0, 0)
- To list ready tasks: SELECT \* FROM tasks WHERE status = 0 ORDER BY "order" ASC, id ASC
- To mark a task as complete: UPDATE tasks SET status = 1, updatedat = CURRENT_TIMESTAMP WHERE id = ?
- To archive a task: UPDATE tasks SET status = 2, updatedat = CURRENT_TIMESTAMP WHERE id = ?
- To backlog a task: UPDATE tasks SET status = 3, updatedat = CURRENT_TIMESTAMP WHERE id = ?
- To get next ready task: SELECT \* FROM tasks WHERE status = 0 ORDER BY "order" ASC, id ASC LIMIT 1

The task operator agent (when enabled) automatically processes tasks with status = 0 (ready), sending the prompt to cursor-runner for execution.

IMPORTANT: When working with cursor-agents (creating, listing, getting status, or deleting agents), use the Python scripts in /cursor/tools/cursor-agents/ directory. These scripts communicate with the cursor-agents service over HTTP:

Agent Management:

- To list all agents: python3 /cursor/tools/cursor-agents/list_agents.py
- To get agent status: python3 /cursor/tools/cursor-agents/get_agent_status.py --name <agent-name>
- To create an agent: python3 /cursor/tools/cursor-agents/create_agent.py --name <name> --target-url <url> [options]
  - Use --queue <queue-name> to assign the agent to a specific queue (defaults to "default" if not specified)
  - Use --schedule <cron-pattern> for recurring agents (e.g., "0 8 \* \* \*" for daily at 8 AM)
  - Use --one-time for one-time agents that run immediately
- To delete an agent: python3 /cursor/tools/cursor-agents/delete_agent.py --name <agent-name>

Queue Management:

- To list all queues: python3 /cursor/tools/cursor-agents/list_queues.py
- To get queue info: python3 /cursor/tools/cursor-agents/get_queue_info.py --queue-name <queue-name>
- To delete an empty queue: python3 /cursor/tools/cursor-agents/delete_queue.py --queue-name <queue-name>
  - Note: Cannot delete the "default" queue or queues with active jobs

Task Operator Management:

- To enable the task operator: python3 /cursor/tools/cursor-agents/enable_task_operator.py [--queue <queue-name>]
  - The task operator automatically processes tasks from the tasks table in the database
  - It checks for incomplete tasks (lowest order first) and sends them to cursor-runner
  - Automatically re-enqueues itself every 5 seconds while enabled
- To disable the task operator: python3 /cursor/tools/cursor-agents/disable_task_operator.py
  - Sets the task_operator system setting to false, stopping re-enqueueing

When creating an agent, the target URL should be the cursor-runner docker networked URL (http://cursor-runner:3001/cursor/iterate/async) with a prompt that this agent will later execute.

Queue Organization: Agents can be organized into queues to avoid queue bloat. By default, agents are created in the "default" queue. Use descriptive queue names like "daily-tasks", "hourly-sync", or "urgent-jobs" to group related agents together.

IMPORTANT: When creating one-time scripts (shell scripts, Python scripts, etc.), place them in /cursor/scripts. This directory is shared and persistent across container restarts. Do not create scripts in the repository directories or other temporary locations.
