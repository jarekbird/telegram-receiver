# PHASE2-013: Create async processing configuration

**Section**: 3. Async Processing Setup
**Subsection**: 3.2
**Task ID**: PHASE2-013

## Description

Create async processing configuration for TypeScript/Node.js. Since this application doesn't have regularly scheduled jobs, we will leverage Node.js's asynchronous nature instead of using a queue system like BullMQ or Sidekiq. This task creates the configuration file that sets up async processing patterns, error handling, and environment-specific settings.

**Rails Implementation Reference:**

- `jarek-va/config/initializers/sidekiq.rb` - Sidekiq initialization with Redis connection, default job options, and logging configuration
- `jarek-va/config/sidekiq.yml` - Environment-specific queue names and concurrency settings
- `jarek-va/config/application.rb` - ActiveJob adapter configuration (line 31: `config.active_job.queue_adapter = :sidekiq`)

**Node.js Implementation:**

- Create `src/config/async.ts` to configure async processing patterns
- Set default async processing options (retry logic, error handling)
- Export async processing configuration for use by async handlers
- Support environment-specific configuration (development, test, production)
- Configure concurrency limits and timeout settings for async operations

## Checklist

- [ ] Create `src/config/async.ts` file
- [ ] Configure default async processing options:
  - [ ] Configure default retry attempts (3 retries to match Rails behavior)
  - [ ] Configure retry delay strategy (exponential backoff)
  - [ ] Configure timeout settings for async operations
  - [ ] Export default async processing options for use by async handlers
- [ ] Configure environment-specific settings:
  - [ ] Development: concurrency limit 2, timeout 30s
  - [ ] Test: concurrency limit 1, timeout 10s
  - [ ] Production: concurrency limit 10, timeout 60s
  - [ ] Load settings based on `NODE_ENV` environment variable
- [ ] Configure error handling:
  - [ ] Set up error logging with full stack traces (matching Rails `backtrace: true`)
  - [ ] Configure error handling patterns for async operations
  - [ ] Export error handling utilities
- [ ] Configure logging:
  - [ ] Set appropriate log level (INFO level, matching Rails `Logger::INFO`)
  - [ ] Ensure async operations are logged appropriately
- [ ] Export configuration:
  - [ ] Export default async processing options
  - [ ] Export environment-specific async configuration
  - [ ] Export helper functions for async operations with proper configuration
  - [ ] Export retry utilities with exponential backoff
- [ ] Add TypeScript types for async processing configuration

## Notes

- This task is part of Phase 2: File-by-File Conversion
- Section: 3. Async Processing Setup
- **Rails Files to Reference:**
  - `jarek-va/config/initializers/sidekiq.rb` - Main Sidekiq configuration:
    - Default job options: `retry: 3, backtrace: true`
    - Logging level: `Logger::INFO`
    - Loads `sidekiq.yml` for concurrency settings
  - `jarek-va/config/sidekiq.yml` - Environment-specific configuration:
    - Default (top-level): concurrency 5, queues: `['default', 'high_priority', 'low_priority']` (used as fallback)
    - Development: concurrency 2, queues: `['default']`
    - Test: concurrency 1, queues: `['default']`
    - Production: concurrency 10, queues: `['critical', 'default', 'high_priority', 'low_priority']`
  - `jarek-va/config/application.rb` - ActiveJob adapter set to `:sidekiq` (line 31)
- **Dependencies:**
  - No external queue dependencies required (using Node.js native async)
  - Uses `NODE_ENV` environment variable for environment-specific settings
- **Implementation Details:**
  - Since this application doesn't have regularly scheduled jobs, we use Node.js's asynchronous nature instead of a queue system
  - Async operations will use `Promise`-based patterns with proper error handling
  - Retry logic should be implemented using exponential backoff (similar to Sidekiq's `wait: :exponentially_longer`)
  - Default retry attempts: 3 (matching Rails `retry: 3`)
  - Error logging should include full stack traces (matching Rails `backtrace: true`)
  - Concurrency limits can be managed using `Promise.all()` with batching or semaphore patterns
  - Environment-specific settings should be loaded based on `NODE_ENV`
  - Consider creating helper functions like `withRetry<T>(fn: () => Promise<T>, options?: RetryOptions): Promise<T>` that apply default retry logic
  - Consider creating helper functions like `withTimeout<T>(promise: Promise<T>, timeoutMs: number): Promise<T>` for timeout handling
- **Key Differences from Rails:**
  - Rails: Uses Sidekiq for background job processing with Redis queues
  - Node.js: Uses native async/await with Promise-based patterns (no queue system needed)
  - Rails: Queue names and concurrency are in `sidekiq.yml` file
  - Node.js: Concurrency is managed via configuration and Promise patterns
  - Rails: Default job options are set globally via `Sidekiq.default_job_options`
  - Node.js: Default async options should be applied via helper functions
- **Testing Considerations:**
  - Test that default async options are applied
  - Test environment-specific configuration loading
  - Test that configuration exports are available for import
  - Test retry logic with exponential backoff
  - Test timeout handling
- Task can be completed independently by a single agent

## Related Tasks

- Previous: PHASE2-012
- Next: PHASE2-014

---

IMPORTANT: When updating system settings (SystemSetting model), you MUST use the cursor-runner-shared-sqlite MCP connection.

IMPORTANT: When working with tasks (creating, querying, updating, or deleting tasks), you MUST use the cursor-runner-shared-sqlite MCP connection. The tasks table is in the shared SQLite database at /app/shared_db/shared.sqlite3.

Tasks Table Schema:

- id: INTEGER PRIMARY KEY AUTOINCREMENT
- prompt: TEXT NOT NULL (the task prompt/description to be executed)
- status: INTEGER NOT NULL DEFAULT 0 (task status enum: 0=ready, 1=complete, 2=archived, 3=backlogged)
- createdat: DATETIME DEFAULT CURRENT_TIMESTAMP
- updatedat: DATETIME DEFAULT CURRENT_TIMESTAMP
- order: INTEGER DEFAULT 0 (lower numbers are processed first)
- uuid: TEXT (unique identifier, indexed)

Task Status Values:

- 0 = ready (ready to be processed by task operator)
- 1 = complete (task has been completed)
- 2 = archived (task has been archived)
- 3 = backlogged (task is in backlog, not ready for processing)

Task Management Examples:

- To create a ready task: INSERT INTO tasks (prompt, "order", status) VALUES ('your prompt here', 0, 0)
- To list ready tasks: SELECT \* FROM tasks WHERE status = 0 ORDER BY "order" ASC, id ASC
- To mark a task as complete: UPDATE tasks SET status = 1, updatedat = CURRENT_TIMESTAMP WHERE id = ?
- To archive a task: UPDATE tasks SET status = 2, updatedat = CURRENT_TIMESTAMP WHERE id = ?
- To backlog a task: UPDATE tasks SET status = 3, updatedat = CURRENT_TIMESTAMP WHERE id = ?
- To get next ready task: SELECT \* FROM tasks WHERE status = 0 ORDER BY "order" ASC, id ASC LIMIT 1

The task operator agent (when enabled) automatically processes tasks with status = 0 (ready), sending the prompt to cursor-runner for execution.

IMPORTANT: When working with cursor-agents (creating, listing, getting status, or deleting agents), use the Python scripts in /cursor/tools/cursor-agents/ directory. These scripts communicate with the cursor-agents service over HTTP:

Agent Management:

- To list all agents: python3 /cursor/tools/cursor-agents/list_agents.py
- To get agent status: python3 /cursor/tools/cursor-agents/get_agent_status.py --name <agent-name>
- To create an agent: python3 /cursor/tools/cursor-agents/create_agent.py --name <name> --target-url <url> [options]
  - Use --queue <queue-name> to assign the agent to a specific queue (defaults to "default" if not specified)
  - Use --schedule <cron-pattern> for recurring agents (e.g., "0 8 \* \* \*" for daily at 8 AM)
  - Use --one-time for one-time agents that run immediately
- To delete an agent: python3 /cursor/tools/cursor-agents/delete_agent.py --name <agent-name>

Queue Management:

- To list all queues: python3 /cursor/tools/cursor-agents/list_queues.py
- To get queue info: python3 /cursor/tools/cursor-agents/get_queue_info.py --queue-name <queue-name>
- To delete an empty queue: python3 /cursor/tools/cursor-agents/delete_queue.py --queue-name <queue-name>
  - Note: Cannot delete the "default" queue or queues with active jobs

Task Operator Management:

- To enable the task operator: python3 /cursor/tools/cursor-agents/enable_task_operator.py [--queue <queue-name>]
  - The task operator automatically processes tasks from the tasks table in the database
  - It checks for incomplete tasks (lowest order first) and sends them to cursor-runner
  - Automatically re-enqueues itself every 5 seconds while enabled
- To disable the task operator: python3 /cursor/tools/cursor-agents/disable_task_operator.py
  - Sets the task_operator system setting to false, stopping re-enqueueing

When creating an agent, the target URL should be the cursor-runner docker networked URL (http://cursor-runner:3001/cursor/iterate/async) with a prompt that this agent will later execute.

Queue Organization: Agents can be organized into queues to avoid queue bloat. By default, agents are created in the "default" queue. Use descriptive queue names like "daily-tasks", "hourly-sync", or "urgent-jobs" to group related agents together.

IMPORTANT: When creating one-time scripts (shell scripts, Python scripts, etc.), place them in /cursor/scripts. This directory is shared and persistent across container restarts. Do not create scripts in the repository directories or other temporary locations.
