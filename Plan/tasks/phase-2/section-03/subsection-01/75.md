# PHASE2-012: Verify async processing dependencies

**Section**: 3. Async Processing Setup
**Subsection**: 3.1
**Task ID**: PHASE2-012

## Description

Verify that all dependencies needed for async processing are available in the TypeScript/Node.js application. Since this application doesn't have regularly scheduled jobs, we will leverage Node.js's asynchronous nature instead of using a queue system like BullMQ or Sidekiq. This task ensures that Node.js native async capabilities are available and no queue system dependencies are needed.

**Rails Implementation Reference:**

- `jarek-va/Gemfile` - Uses `sidekiq` gem (~> 7.0) for background job processing (line 25)
- `jarek-va/config/sidekiq.yml` - Sidekiq configuration with queue definitions and concurrency settings
- `jarek-va/config/initializers/sidekiq.rb` - Sidekiq initialization with Redis connection and default job options
- `jarek-va/app/jobs/application_job.rb` - Base job class using Sidekiq adapter
- `jarek-va/app/jobs/telegram_message_job.rb` - Example job using Sidekiq for async processing

**Node.js Implementation:**

- Node.js native async/await and Promise support (built-in, no dependencies needed)
- No queue system dependencies required (BullMQ is not needed)
- Verify that Node.js version supports async/await (Node.js 8+)
- Ensure TypeScript is configured for async/await support

## Checklist

- [ ] Verify Node.js version supports async/await (Node.js 8+ required, Node.js 14+ recommended)
- [ ] Verify TypeScript configuration supports async/await:
  - [ ] Check `tsconfig.json` has appropriate `target` setting (ES2017+ for async/await)
  - [ ] Verify `lib` includes Promise support
- [ ] Verify no queue system dependencies are needed:
  - [ ] Confirm `bullmq` is NOT in package.json (or can be removed if present)
  - [ ] Note: `ioredis` may still be needed for Redis operations (not for queues)
- [ ] Test async/await functionality:
  - [ ] Create a simple test file with async/await to verify it works
  - [ ] Verify Promise.all, Promise.race, and other Promise utilities work
- [ ] Document that async processing will use native Node.js capabilities

## Notes

- This task is part of Phase 2: File-by-File Conversion
- Section: 3. Async Processing Setup
- **Rails Files to Reference:**
  - `jarek-va/Gemfile` - Sidekiq gem dependency (line 25) - Note: We're NOT using a queue system equivalent
  - `jarek-va/config/sidekiq.yml` - Sidekiq queue configuration - Note: Not applicable, we use async patterns
  - `jarek-va/config/initializers/sidekiq.rb` - Sidekiq initialization - Note: Not applicable, we use async utilities
  - `jarek-va/app/jobs/application_job.rb` - Base job class using Sidekiq - Note: We use async handlers instead
- **Dependencies:**
  - Node.js native async/await support (built-in, no dependencies needed)
  - TypeScript async/await support (built-in with proper tsconfig)
  - Note: Redis may still be used for other purposes (not for queues)
  - Note: `ioredis` may still be in package.json for Redis operations, but not for queue system
- **Implementation Details:**
  - Since this application doesn't have regularly scheduled jobs, we use Node.js native async capabilities
  - No queue system is needed - operations run asynchronously using Promise-based patterns
  - Async operations will use `async/await` with proper error handling and retry logic
  - Check `telegram-receiver/package.json` to verify no queue system dependencies are needed
  - If `bullmq` is present, it can be removed (not needed for this application)
- **Key Differences from Rails:**
  - Rails: Uses Sidekiq gem with Redis for background job processing
  - Node.js: Uses native async/await with Promise-based patterns (no queue system needed)
  - Rails: Jobs are enqueued and processed by workers
  - Node.js: Operations are executed asynchronously directly
- Task can be completed independently by a single agent

## Related Tasks

- Previous: PHASE2-011
- Next: PHASE2-013

---

IMPORTANT: When updating system settings (SystemSetting model), you MUST use the cursor-runner-shared-sqlite MCP connection.

IMPORTANT: When working with tasks (creating, querying, updating, or deleting tasks), you MUST use the cursor-runner-shared-sqlite MCP connection. The tasks table is in the shared SQLite database at /app/shared_db/shared.sqlite3.

Tasks Table Schema:

- id: INTEGER PRIMARY KEY AUTOINCREMENT
- prompt: TEXT NOT NULL (the task prompt/description to be executed)
- status: INTEGER NOT NULL DEFAULT 0 (task status enum: 0=ready, 1=complete, 2=archived, 3=backlogged)
- createdat: DATETIME DEFAULT CURRENT_TIMESTAMP
- updatedat: DATETIME DEFAULT CURRENT_TIMESTAMP
- order: INTEGER DEFAULT 0 (lower numbers are processed first)
- uuid: TEXT (unique identifier, indexed)

Task Status Values:

- 0 = ready (ready to be processed by task operator)
- 1 = complete (task has been completed)
- 2 = archived (task has been archived)
- 3 = backlogged (task is in backlog, not ready for processing)

Task Management Examples:

- To create a ready task: INSERT INTO tasks (prompt, "order", status) VALUES ('your prompt here', 0, 0)
- To list ready tasks: SELECT \* FROM tasks WHERE status = 0 ORDER BY "order" ASC, id ASC
- To mark a task as complete: UPDATE tasks SET status = 1, updatedat = CURRENT_TIMESTAMP WHERE id = ?
- To archive a task: UPDATE tasks SET status = 2, updatedat = CURRENT_TIMESTAMP WHERE id = ?
- To backlog a task: UPDATE tasks SET status = 3, updatedat = CURRENT_TIMESTAMP WHERE id = ?
- To get next ready task: SELECT \* FROM tasks WHERE status = 0 ORDER BY "order" ASC, id ASC LIMIT 1

The task operator agent (when enabled) automatically processes tasks with status = 0 (ready), sending the prompt to cursor-runner for execution.

IMPORTANT: When working with cursor-agents (creating, listing, getting status, or deleting agents), use the Python scripts in /cursor/tools/cursor-agents/ directory. These scripts communicate with the cursor-agents service over HTTP:

Agent Management:

- To list all agents: python3 /cursor/tools/cursor-agents/list_agents.py
- To get agent status: python3 /cursor/tools/cursor-agents/get_agent_status.py --name <agent-name>
- To create an agent: python3 /cursor/tools/cursor-agents/create_agent.py --name <name> --target-url <url> [options]
  - Use --queue <queue-name> to assign the agent to a specific queue (defaults to "default" if not specified)
  - Use --schedule <cron-pattern> for recurring agents (e.g., "0 8 \* \* \*" for daily at 8 AM)
  - Use --one-time for one-time agents that run immediately
- To delete an agent: python3 /cursor/tools/cursor-agents/delete_agent.py --name <agent-name>

Queue Management:

- To list all queues: python3 /cursor/tools/cursor-agents/list_queues.py
- To get queue info: python3 /cursor/tools/cursor-agents/get_queue_info.py --queue-name <queue-name>
- To delete an empty queue: python3 /cursor/tools/cursor-agents/delete_queue.py --queue-name <queue-name>
  - Note: Cannot delete the "default" queue or queues with active jobs

Task Operator Management:

- To enable the task operator: python3 /cursor/tools/cursor-agents/enable_task_operator.py [--queue <queue-name>]
  - The task operator automatically processes tasks from the tasks table in the database
  - It checks for incomplete tasks (lowest order first) and sends them to cursor-runner
  - Automatically re-enqueues itself every 5 seconds while enabled
- To disable the task operator: python3 /cursor/tools/cursor-agents/disable_task_operator.py
  - Sets the task_operator system setting to false, stopping re-enqueueing

When creating an agent, the target URL should be the cursor-runner docker networked URL (http://cursor-runner:3001/cursor/iterate/async) with a prompt that this agent will later execute.

Queue Organization: Agents can be organized into queues to avoid queue bloat. By default, agents are created in the "default" queue. Use descriptive queue names like "daily-tasks", "hourly-sync", or "urgent-jobs" to group related agents together.

IMPORTANT: When creating one-time scripts (shell scripts, Python scripts, etc.), place them in /cursor/scripts. This directory is shared and persistent across container restarts. Do not create scripts in the repository directories or other temporary locations.
