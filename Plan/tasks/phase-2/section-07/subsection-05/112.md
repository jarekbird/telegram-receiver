# PHASE2-049: Write SpeechToTextService unit tests

**Section**: 7. ElevenLabs Services Conversion
**Subsection**: 7.5
**Task ID**: PHASE2-049

## Description

Write comprehensive unit tests for the ElevenLabsSpeechToTextService class, covering all public methods, error handling, and edge cases. Reference `jarek-va/app/services/eleven_labs_speech_to_text_service.rb` for the complete implementation details and behavior to test.

**Rails Reference**: `jarek-va/app/services/eleven_labs_speech_to_text_service.rb`

## Checklist

### Test File Setup

- [ ] Create `tests/unit/services/elevenlabs-speech-to-text-service.test.ts`
- [ ] Import ElevenLabsSpeechToTextService and all error classes
- [ ] Set up HTTP request mocking (use appropriate mocking library for Node.js HTTP client)
- [ ] Set up file system mocking for file operations
- [ ] Create test fixtures for audio file paths and mock audio data

### Constructor Tests

- [ ] Test constructor with valid API key (from parameter)
- [ ] Test constructor with valid API key (from config/environment)
- [ ] Test constructor throws Error when API key is blank/null/undefined
- [ ] Test constructor uses default timeout (60 seconds) when not provided
- [ ] Test constructor uses custom timeout when provided
- [ ] Test constructor uses default model_id ('scribe_v1') when not provided
- [ ] Test constructor uses custom model_id when provided
- [ ] Test constructor uses model_id from config when not provided

### `transcribe` Method Tests (File Path)

- [ ] Test successful transcription with valid audio file
- [ ] Test transcribe sends correct multipart form data (file, model_id)
- [ ] Test transcribe includes language parameter when provided
- [ ] Test transcribe does not include language parameter when not provided
- [ ] Test transcribe sets correct HTTP headers (xi-api-key, Content-Type)
- [ ] Test transcribe sends POST request to correct endpoint (`https://api.elevenlabs.io/v1/speech-to-text`)
- [ ] Test transcribe extracts filename from file path correctly
- [ ] Test transcribe reads file as binary data (using binary read operation, not text)
- [ ] Test transcribe parses JSON response and extracts text field
- [ ] Test transcribe returns transcribed text string
- [ ] Test transcribe logs info when sending audio file (include file path)
- [ ] Test transcribe logs POST request path to endpoint
- [ ] Test transcribe logs response code and message on successful request
- [ ] Test transcribe logs info on successful transcription (include first 50 chars)

### `transcribe` Method Error Handling Tests

- [ ] Test transcribe throws Error when audioFilePath is blank/null/undefined
- [ ] Test transcribe throws Error when audio file does not exist
- [ ] Test transcribe throws TranscriptionError when HTTP response is not successful (non-2xx)
- [ ] Test transcribe throws TranscriptionError when response text field is blank/missing
- [ ] Test transcribe throws InvalidResponseError when JSON parsing fails
- [ ] Test transcribe throws ConnectionError on network connection failures (ECONNREFUSED, EHOSTUNREACH, SocketError)
- [ ] Test transcribe throws TimeoutError on request timeout (OpenTimeout, ReadTimeout)
- [ ] Test transcribe handles file not found errors (ENOENT) and throws Error with descriptive message including original error
- [ ] Test transcribe extracts error message from error response JSON (detail/error/message fields, in that priority order)
- [ ] Test transcribe logs error details for API errors (response code and body preview)
- [ ] Test transcribe logs error when error response JSON parsing fails (falls back to default error message)

### `transcribeIo` Method Tests (IO Object)

- [ ] Test successful transcription with Buffer input
- [ ] Test successful transcription with ReadableStream input
- [ ] Test transcribeIo sends correct multipart form data (file, model_id)
- [ ] Test transcribeIo includes language parameter when provided
- [ ] Test transcribeIo does not include language parameter when not provided
- [ ] Test transcribeIo uses default filename ('audio.ogg') when not provided
- [ ] Test transcribeIo uses custom filename when provided
- [ ] Test transcribeIo handles stream rewinding if stream supports it
- [ ] Test transcribeIo reads IO/stream content into memory correctly
- [ ] Test transcribeIo sets correct HTTP headers (xi-api-key, Content-Type)
- [ ] Test transcribeIo sends POST request to correct endpoint
- [ ] Test transcribeIo parses JSON response and extracts text field
- [ ] Test transcribeIo returns transcribed text string
- [ ] Test transcribeIo logs info when sending audio IO (include filename)
- [ ] Test transcribeIo logs POST request path to endpoint
- [ ] Test transcribeIo logs response code and message on successful request
- [ ] Test transcribeIo logs info on successful transcription (include first 50 chars)

### `transcribeIo` Method Error Handling Tests

- [ ] Test transcribeIo throws Error when audioIo is null/undefined
- [ ] Test transcribeIo throws TranscriptionError when HTTP response is not successful (non-2xx)
- [ ] Test transcribeIo throws TranscriptionError when response text field is blank/missing
- [ ] Test transcribeIo throws InvalidResponseError when JSON parsing fails
- [ ] Test transcribeIo throws ConnectionError on network connection failures
- [ ] Test transcribeIo throws TimeoutError on request timeout
- [ ] Test transcribeIo extracts error message from error response JSON (detail/error/message fields, in that priority order)
- [ ] Test transcribeIo logs error details for API errors (response code and body preview)
- [ ] Test transcribeIo logs error when error response JSON parsing fails (falls back to default error message)

### Edge Cases and Integration Tests

- [ ] Test service handles empty audio file gracefully
- [ ] Test service handles very large audio files
- [ ] Test service handles special characters in file paths
- [ ] Test service handles different audio file formats
- [ ] Test service handles concurrent transcription requests
- [ ] Test service uses correct model_id from instance configuration
- [ ] Test service respects timeout configuration

### Coverage Requirements

- [ ] Achieve >80% code coverage
- [ ] Ensure all public methods are tested
- [ ] Ensure all error paths are tested
- [ ] Ensure all error classes are tested

## Implementation Notes

- This task is part of Phase 2: File-by-File Conversion
- Section: 7. ElevenLabs Services Conversion
- **Rails Implementation**: `jarek-va/app/services/eleven_labs_speech_to_text_service.rb`
- The service should already be implemented from previous tasks (PHASE2-045 through PHASE2-048)
- Use Jest or similar testing framework
- Mock HTTP requests using appropriate library (e.g., `nock`, `msw`, or `jest.mock` for fetch/axios)
- Mock file system operations using `jest.mock('fs')` or similar
- Test file should be placed in `tests/unit/services/` directory
- Follow the testing patterns established in the project (see `tests/README.md` and `tests/helpers/testUtils.ts`)
- Error classes to test: `Error`, `ConnectionError`, `TimeoutError`, `InvalidResponseError`, `TranscriptionError`
- Method names in TypeScript: `transcribe` (for file path) and `transcribeIo` (for IO object, camelCase)
- Task can be completed independently by a single agent

## Related Tasks

- Previous: PHASE2-048
- Next: PHASE2-050

## Definition of Done

This document defines the criteria for task completion. The review agent uses these definitions to evaluate whether a task has been completed successfully.

### 1. CODE/FILE WRITING TASKS

**Description**: Tasks that involve writing, creating, modifying, or implementing SOURCE CODE FILES that need to be committed to git.

**Definition of Done**: "A Pull Request was created OR code was pushed to origin with the task complete"

**Examples**:
- Creating new source code files
- Modifying existing source code files
- Implementing features, functions, classes, modules
- Writing tests, specs
- Refactoring code
- Fixing bugs in source code

### 2. SYSTEM/ENVIRONMENT OPERATION TASKS

**Description**: Tasks involving installing dependencies, running builds, installing packages, running migrations, executing install scripts, etc.

**Definition of Done**: "The required operation must complete successfully with no errors, and the expected artifacts must be created. If any part of the operation fails, the task is NOT complete."

**Important Notes**:
- Installing dependencies requires packages to actually be installed successfully
- Updating package.json is NOT enough
- If the output mentions environmental issues, errors, warnings, or failed operations, the task is NOT complete

**Examples**:
- Installing npm packages, pip packages, gem dependencies
- Running database migrations
- Building/compiling projects
- Setting up development environments
- Running install scripts

### 3. SIMPLE REQUESTS/QUESTIONS/DATA OPERATIONS

**Description**: Tasks involving asking questions, requesting information, explanations, clarifications, database queries/updates, data manipulation, executing scripts/commands that don't create source code files, etc.

**Definition of Done**: "The request was completed or the question was answered"

**Examples**:
- Answering questions
- Providing explanations
- Querying databases
- Reading/updating data
- Executing commands that don't create source code files
- Information gathering tasks



---

IMPORTANT: When updating system settings (SystemSetting model), you MUST use the cursor-runner-shared-sqlite MCP connection.

IMPORTANT: When working with tasks (creating, querying, updating, or deleting tasks), you MUST use the cursor-runner-shared-sqlite MCP connection. The tasks table is in the shared SQLite database at /app/shared_db/shared.sqlite3.

Tasks Table Schema:

- id: INTEGER PRIMARY KEY AUTOINCREMENT
- prompt: TEXT NOT NULL (the task prompt/description to be executed)
- status: INTEGER NOT NULL DEFAULT 0 (task status enum: 0=ready, 1=complete, 2=archived, 3=backlogged)
- createdat: DATETIME DEFAULT CURRENT_TIMESTAMP
- updatedat: DATETIME DEFAULT CURRENT_TIMESTAMP
- order: INTEGER DEFAULT 0 (lower numbers are processed first)
- uuid: TEXT (unique identifier, indexed)

Task Status Values:

- 0 = ready (ready to be processed by task operator)
- 1 = complete (task has been completed)
- 2 = archived (task has been archived)
- 3 = backlogged (task is in backlog, not ready for processing)

Task Management Examples:

- To create a ready task: INSERT INTO tasks (prompt, "order", status) VALUES ('your prompt here', 0, 0)
- To list ready tasks: SELECT \* FROM tasks WHERE status = 0 ORDER BY "order" ASC, id ASC
- To mark a task as complete: UPDATE tasks SET status = 1, updatedat = CURRENT_TIMESTAMP WHERE id = ?
- To archive a task: UPDATE tasks SET status = 2, updatedat = CURRENT_TIMESTAMP WHERE id = ?
- To backlog a task: UPDATE tasks SET status = 3, updatedat = CURRENT_TIMESTAMP WHERE id = ?
- To get next ready task: SELECT \* FROM tasks WHERE status = 0 ORDER BY "order" ASC, id ASC LIMIT 1

The task operator agent (when enabled) automatically processes tasks with status = 0 (ready), sending the prompt to cursor-runner for execution.

IMPORTANT: When working with cursor-agents (creating, listing, getting status, or deleting agents), use the Python scripts in /cursor/tools/cursor-agents/ directory. These scripts communicate with the cursor-agents service over HTTP:

Agent Management:

- To list all agents: python3 /cursor/tools/cursor-agents/list_agents.py
- To get agent status: python3 /cursor/tools/cursor-agents/get_agent_status.py --name <agent-name>
- To create an agent: python3 /cursor/tools/cursor-agents/create_agent.py --name <name> --target-url <url> [options]
  - Use --queue <queue-name> to assign the agent to a specific queue (defaults to "default" if not specified)
  - Use --schedule <cron-pattern> for recurring agents (e.g., "0 8 \* \* \*" for daily at 8 AM)
  - Use --one-time for one-time agents that run immediately
- To delete an agent: python3 /cursor/tools/cursor-agents/delete_agent.py --name <agent-name>

Queue Management:

- To list all queues: python3 /cursor/tools/cursor-agents/list_queues.py
- To get queue info: python3 /cursor/tools/cursor-agents/get_queue_info.py --queue-name <queue-name>
- To delete an empty queue: python3 /cursor/tools/cursor-agents/delete_queue.py --queue-name <queue-name>
  - Note: Cannot delete the "default" queue or queues with active jobs

Task Operator Management:

- To enable the task operator: python3 /cursor/tools/cursor-agents/enable_task_operator.py [--queue <queue-name>]
  - The task operator automatically processes tasks from the tasks table in the database
  - It checks for incomplete tasks (lowest order first) and sends them to cursor-runner
  - Automatically re-enqueues itself every 5 seconds while enabled
- To disable the task operator: python3 /cursor/tools/cursor-agents/disable_task_operator.py
  - Sets the task_operator system setting to false, stopping re-enqueueing

When creating an agent, the target URL should be the cursor-runner docker networked URL (http://cursor-runner:3001/cursor/iterate/async) with a prompt that this agent will later execute.

Queue Organization: Agents can be organized into queues to avoid queue bloat. By default, agents are created in the "default" queue. Use descriptive queue names like "daily-tasks", "hourly-sync", or "urgent-jobs" to group related agents together.

IMPORTANT: When creating one-time scripts (shell scripts, Python scripts, etc.), place them in /cursor/scripts. This directory is shared and persistent across container restarts. Do not create scripts in the repository directories or other temporary locations.
