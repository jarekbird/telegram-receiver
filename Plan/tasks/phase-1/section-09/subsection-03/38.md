# PHASE1-038: Create docker-compose.yml for development

**Section**: 9. Docker Configuration
**Subsection**: 9.3
**Task ID**: PHASE1-038

## Description

Create a development docker-compose.yml file for the telegram-receiver Node.js/TypeScript application. The docker-compose.yml should configure services needed for local development, including the application service, Redis service (for BullMQ job queue), shared volumes, and development-specific settings like hot reloading and volume mounts. Reference the jarek-va docker-compose.yml (`/cursor/repositories/jarek-va/docker-compose.yml`) for patterns, but adapt for Node.js/TypeScript development needs.

## Checklist

- [ ] Create `docker-compose.yml` file in project root
- [ ] Define `app` service:
  - [ ] Set build context to current directory (`.`)
  - [ ] Set dockerfile path to `Dockerfile`
  - [ ] Set container name to `telegram-receiver-app-dev` (or similar)
  - [ ] Map port `3000:3000` for direct access during development
  - [ ] Add `env_file` directive pointing to `.env.development` for environment variable loading
  - [ ] Set `NODE_ENV` environment variable to `development`
  - [ ] Set `PORT` environment variable to `3000` (or use from `.env.development`)
  - [ ] Set `REDIS_URL` to `redis://redis:6379` (using Redis service name, optionally add `/0` for database number to match jarek-va pattern)
  - [ ] Set `CURSOR_RUNNER_URL` to `http://cursor-runner:3001` (if cursor-runner is available)
  - [ ] Set `CURSOR_RUNNER_TIMEOUT` to `${CURSOR_RUNNER_TIMEOUT:-300}` (matching jarek-va pattern)
  - [ ] Set other environment variables from `.env.example` (TELEGRAM_BOT_TOKEN, LOG_LEVEL=debug, etc.)
  - [ ] Add volume mount for source code (`./src:/app/src`) for hot reloading
  - [ ] Add volume mount for node_modules (`./node_modules:/app/node_modules`) to persist dependencies
  - [ ] Add volume mount for shared SQLite database (`shared_sqlite_db:/app/shared_db`) for cross-service database access
  - [ ] Set command to `npm run dev` (which runs `nodemon --exec ts-node src/index.ts` for hot reloading)
  - [ ] **Note**: This command is for Docker container deployment only. Developers should NOT run the server manually for testing - use automated tests instead.
  - [ ] Set restart policy to `unless-stopped` or `on-failure` for development
  - [ ] Add depends_on for `redis` service
  - [ ] Add to `virtual-assistant-network` network
  - [ ] Optionally add healthcheck: `curl -f http://localhost:3000/health` (useful for development debugging)
- [ ] Define `redis` service:
  - [ ] Use `redis:7-alpine` image (matching jarek-va)
  - [ ] Set container name to `telegram-receiver-redis` (or similar)
  - [ ] Configure Redis persistence with `--appendonly yes` command (matching jarek-va)
  - [ ] Map port `6379:6379` for direct Redis access during development
  - [ ] Add volume for Redis data persistence (`shared_redis_data:/data`)
  - [ ] Set restart policy to `unless-stopped`
  - [ ] Add to `virtual-assistant-network` network
  - [ ] Add healthcheck using `redis-cli ping` with appropriate intervals and timeouts
- [ ] Define volumes:
  - [ ] `shared_redis_data` volume (driver: local, name: shared_redis_data) - shared across services
  - [ ] `shared_sqlite_db` volume (driver: local, name: shared_sqlite_db) - shared across services for cross-service database access
- [ ] Define networks:
  - [ ] Reference `virtual-assistant-network` as external network (matching jarek-va pattern for service communication)
  - [ ] Network name: `virtual-assistant-network`
  - [ ] Set `external: true` to use existing network created by jarek-va or other services
- [ ] Add development-specific configurations:
  - [ ] Use `env_file` directive in app service to load `.env.development` file
  - [ ] Ensure source code changes trigger hot reload (via nodemon which watches `src/` directory)
  - [ ] Configure logging to stdout for development visibility (matches jarek-va `RAILS_LOG_TO_STDOUT=true` pattern)
  - [ ] Ensure all services are connected to the same network for inter-service communication

## Notes

- This task is part of Phase 1: Basic Node.js API Infrastructure
- Section: 9. Docker Configuration
- Task can be completed independently by a single agent
- Reference the jarek-va docker-compose.yml (`/cursor/repositories/jarek-va/docker-compose.yml`) for patterns:
  - Redis service configuration
  - Shared volume setup (Redis data, SQLite database)
  - Network configuration
  - Healthcheck patterns
- The development docker-compose.yml should enable:
  - Hot reloading of TypeScript source code changes
  - Direct port access for testing
  - Redis access for BullMQ job queue
  - Shared database access if using shared SQLite database
  - Easy debugging and development workflow
- Environment variables should match those defined in `.env.example`:
  - `NODE_ENV=development`
  - `PORT=3000`
  - `REDIS_URL=redis://redis:6379` (optionally `redis://redis:6379/0` to match jarek-va pattern with database number)
  - `CURSOR_RUNNER_URL=http://cursor-runner:3001`
  - `CURSOR_RUNNER_TIMEOUT=300` (matching jarek-va default)
  - `TELEGRAM_BOT_TOKEN` (from environment or .env file)
  - `LOG_LEVEL=debug` (for development)
- The `virtual-assistant-network` should be created externally (by jarek-va or manually) and referenced as `external: true` to enable cross-service communication
- Shared volumes (`shared_redis_data` and `shared_sqlite_db`) enable data persistence and cross-service access, matching jarek-va patterns
- The app service should use `npm run dev` command which runs `nodemon --exec ts-node src/index.ts` for hot reloading
- **Important**: The `npm run dev` command in docker-compose is for Docker container deployment only. Developers should use automated tests (`npm test`, `npm run test:integration`) instead of running the server manually for testing
- Volume mounts for `src/` directory enable live code reloading without rebuilding the Docker image
- The `node_modules` volume mount ensures dependencies persist and don't need to be reinstalled on container restart

## Related Tasks

- Previous: PHASE1-037
- Next: PHASE1-039


---

IMPORTANT: When updating system settings (SystemSetting model), you MUST use the cursor-runner-shared-sqlite MCP connection.

IMPORTANT: When working with tasks (creating, querying, updating, or deleting tasks), you MUST use the cursor-runner-shared-sqlite MCP connection. The tasks table is in the shared SQLite database at /app/shared_db/shared.sqlite3.

Tasks Table Schema:
- id: INTEGER PRIMARY KEY AUTOINCREMENT
- prompt: TEXT NOT NULL (the task prompt/description to be executed)
- status: INTEGER NOT NULL DEFAULT 0 (task status enum: 0=ready, 1=complete, 2=archived, 3=backlogged)
- createdat: DATETIME DEFAULT CURRENT_TIMESTAMP
- updatedat: DATETIME DEFAULT CURRENT_TIMESTAMP
- order: INTEGER DEFAULT 0 (lower numbers are processed first)
- uuid: TEXT (unique identifier, indexed)

Task Status Values:
- 0 = ready (ready to be processed by task operator)
- 1 = complete (task has been completed)
- 2 = archived (task has been archived)
- 3 = backlogged (task is in backlog, not ready for processing)

Task Management Examples:
- To create a ready task: INSERT INTO tasks (prompt, "order", status) VALUES ('your prompt here', 0, 0)
- To list ready tasks: SELECT * FROM tasks WHERE status = 0 ORDER BY "order" ASC, id ASC
- To mark a task as complete: UPDATE tasks SET status = 1, updatedat = CURRENT_TIMESTAMP WHERE id = ?
- To archive a task: UPDATE tasks SET status = 2, updatedat = CURRENT_TIMESTAMP WHERE id = ?
- To backlog a task: UPDATE tasks SET status = 3, updatedat = CURRENT_TIMESTAMP WHERE id = ?
- To get next ready task: SELECT * FROM tasks WHERE status = 0 ORDER BY "order" ASC, id ASC LIMIT 1

The task operator agent (when enabled) automatically processes tasks with status = 0 (ready), sending the prompt to cursor-runner for execution.

IMPORTANT: When working with cursor-agents (creating, listing, getting status, or deleting agents), use the Python scripts in /cursor/tools/cursor-agents/ directory. These scripts communicate with the cursor-agents service over HTTP:

Agent Management:
- To list all agents: python3 /cursor/tools/cursor-agents/list_agents.py
- To get agent status: python3 /cursor/tools/cursor-agents/get_agent_status.py --name <agent-name>
- To create an agent: python3 /cursor/tools/cursor-agents/create_agent.py --name <name> --target-url <url> [options]
  - Use --queue <queue-name> to assign the agent to a specific queue (defaults to "default" if not specified)
  - Use --schedule <cron-pattern> for recurring agents (e.g., "0 8 * * *" for daily at 8 AM)
  - Use --one-time for one-time agents that run immediately
- To delete an agent: python3 /cursor/tools/cursor-agents/delete_agent.py --name <agent-name>

Queue Management:
- To list all queues: python3 /cursor/tools/cursor-agents/list_queues.py
- To get queue info: python3 /cursor/tools/cursor-agents/get_queue_info.py --queue-name <queue-name>
- To delete an empty queue: python3 /cursor/tools/cursor-agents/delete_queue.py --queue-name <queue-name>
  - Note: Cannot delete the "default" queue or queues with active jobs

Task Operator Management:
- To enable the task operator: python3 /cursor/tools/cursor-agents/enable_task_operator.py [--queue <queue-name>]
  - The task operator automatically processes tasks from the tasks table in the database
  - It checks for incomplete tasks (lowest order first) and sends them to cursor-runner
  - Automatically re-enqueues itself every 5 seconds while enabled
- To disable the task operator: python3 /cursor/tools/cursor-agents/disable_task_operator.py
  - Sets the task_operator system setting to false, stopping re-enqueueing

When creating an agent, the target URL should be the cursor-runner docker networked URL (http://cursor-runner:3001/cursor/iterate/async) with a prompt that this agent will later execute.

Queue Organization: Agents can be organized into queues to avoid queue bloat. By default, agents are created in the "default" queue. Use descriptive queue names like "daily-tasks", "hourly-sync", or "urgent-jobs" to group related agents together.

IMPORTANT: When creating one-time scripts (shell scripts, Python scripts, etc.), place them in /cursor/scripts. This directory is shared and persistent across container restarts. Do not create scripts in the repository directories or other temporary locations.
